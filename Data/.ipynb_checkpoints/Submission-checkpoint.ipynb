{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just raw data\n",
    "xtrain0 = pd.read_csv(\"Xtr0.csv\", \" \", header=None)\n",
    "xtest0 = pd.read_csv(\"Xte0.csv\", \" \", header=None)\n",
    "y0 = pd.read_csv(\"Ytr0.csv\", index_col=0,header=None)\n",
    "xtrain0.columns = ['N']\n",
    "xtest0.columns = ['N']\n",
    "\n",
    "xtrain1 = pd.read_csv(\"Xtr1.csv\", \" \", header=None)\n",
    "xtest1 = pd.read_csv(\"Xte1.csv\", \" \", header=None)\n",
    "y1 = pd.read_csv(\"Ytr1.csv\", index_col=0,header=None)\n",
    "xtrain1.columns = ['N']\n",
    "xtest1.columns = ['N']\n",
    "\n",
    "xtrain2 = pd.read_csv(\"Xtr2.csv\", \" \", header=None)\n",
    "xtest2 = pd.read_csv(\"Xte2.csv\", \" \", header=None)\n",
    "y2 = pd.read_csv(\"Ytr2.csv\", index_col=0,header=None)\n",
    "xtrain2.columns = ['N']\n",
    "xtest2.columns = ['N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuc_3 = []\n",
    "# for i in ['A', 'T', 'C', 'G']:\n",
    "#     for j in ['A', 'T', 'C', 'G']:\n",
    "#         for k in ['A', 'T', 'C', 'G']:\n",
    "#             for l in ['A', 'T', 'C', 'G']:\n",
    "#                 for m in ['A', 'T', 'C', 'G']:\n",
    "#                     for n in ['A', 'T', 'C', 'G']:\n",
    "#                         for p in ['A', 'T', 'C', 'G']:\n",
    "#                             nuc_3.append(i+j+k+l+n+m+p)\n",
    "                    \n",
    "# for i in nuc_3:\n",
    "#     xtrain0[i] = 1.*xtrain0.N.apply(lambda x: i in x)\n",
    "#     xtrain1[i] = 1.*xtrain1.N.apply(lambda x: i in x)\n",
    "#     xtrain2[i] = 1.*xtrain2.N.apply(lambda x: i in x)\n",
    "#     xtest0[i] = 1.*xtest0.N.apply(lambda x: i in x)\n",
    "#     xtest1[i] = 1.*xtest1.N.apply(lambda x: i in x)\n",
    "#     xtest2[i] = 1.*xtest2.N.apply(lambda x: i in x)\n",
    "\n",
    "xtrain0 = xtrain0.drop(\"N\", axis = 1)\n",
    "xtrain1 = xtrain1.drop(\"N\", axis = 1)\n",
    "xtrain2 = xtrain2.drop(\"N\", axis = 1)\n",
    "xtest0 = xtest0.drop(\"N\", axis = 1)\n",
    "xtest1 = xtest1.drop(\"N\", axis = 1)\n",
    "xtest2 = xtest2.drop(\"N\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prepares the data according to the spectrum kernel\n",
    "def prepare_data_kmers(x_data, y_data, test_data, k, l):\n",
    "    '''\n",
    "    x_data - Sequence data\n",
    "    y_data - correctly labeled details\n",
    "    test_data - if not None will output transformed data for test\n",
    "    k - sequence lengths\n",
    "    l - number of features to take #this was not properly implemented\n",
    "    '''\n",
    "    #this section finds all possible permutations of the four possibilities, then eleiminates duplicates\n",
    "    poss = ['A','C','G','T','C','G','T','A','G','T','A','C','T','A','C','G']\n",
    "    comb = []\n",
    "    for j in itertools.combinations_with_replacement(poss, k):\n",
    "        comb.append(list(j))\n",
    "    comb = np.asarray(comb)\n",
    "    comb= np.unique(comb, axis = 0)\n",
    "    #joins as one string\n",
    "    comb =[\"\".join(i) for i in comb[:,:].astype(str)]\n",
    "    #initialize the counting of occurences of each string in data occurences, stores for each one\n",
    "    features= np.zeros(shape=(len(x_data), len(comb)))\n",
    "    #saves the features\n",
    "    for m in range(0,len(x_data)):\n",
    "        s = x_data[m]\n",
    "        li = [ s[i:i+k] for i in range(len(s)-k+1) ]\n",
    "        counter = collections.Counter(li)\n",
    "        i=0\n",
    "        for j in comb:\n",
    "            features[m][i] = counter[j]\n",
    "            i=i+1\n",
    "    temp1=features[y_data==1]\n",
    "    temp1_sum=temp1.sum(axis=0)\n",
    "    ind1 = np.argpartition(temp1_sum, -l)[-l:]\n",
    "    temp0=features[y_data==0]\n",
    "    temp0_sum=temp0.sum(axis=0)\n",
    "    ind0 = np.argpartition(temp0_sum, -l)[-l:]\n",
    "    index = np.append(ind0,ind1)\n",
    "    extracted_feature_data = features[:,index]\n",
    "    extracted_feature_data /= np.max(np.abs(extracted_feature_data),axis=0)\n",
    "    #this says if we want the data for only one set or for two (ie test and train)\n",
    "    if test_data.size != 0:\n",
    "        extracted_test_data= np.zeros(shape=(len(test_data), len(comb)))\n",
    "        for m in range(0,len(test_data)):\n",
    "            s = test_data[m]\n",
    "            li = [ s[i:i+k] for i in range(len(s)-k+1) ]\n",
    "            counter = collections.Counter(li)\n",
    "            i=0\n",
    "            for j in comb:\n",
    "                extracted_test_data[m][i] = counter[j]\n",
    "                i=i+1\n",
    "        extracted_test_data = extracted_test_data[:,[index]]\n",
    "        extracted_test_data /= np.max(np.abs(extracted_test_data),axis=0)\n",
    "\n",
    "        return extracted_feature_data, extracted_test_data\n",
    "    else:\n",
    "        return extracted_feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain0 = np.array(xtrain0)\n",
    "xtrain1 = np.array(xtrain1)\n",
    "xtrain2 = np.array(xtrain2)\n",
    "y0 = np.array(y0)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "\n",
    "fulldataX = np.concatenate((np.concatenate((xtrain0, xtrain1)), xtrain2))\n",
    "fulldataY = np.concatenate((np.concatenate((y0, y1)), y2))\n",
    "\n",
    "# print(fulldataX.shape)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(fulldataX, fulldataY, test_size=0.3)\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import pandas as pd\n",
    "x,x_test_f = prepare_data_kmers(fulldataX, fulldataY, fulldataX, k=5, l=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, fulldataY, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfoming Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression(features, target, num_steps, learning_rate, regularizer ):\n",
    "    \n",
    "    target = pd.DataFrame(target)\n",
    "    target = np.array(target.iloc[:,0])\n",
    "    target.astype(float) \n",
    "    features = np.array(features)\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    m = features.shape[0]\n",
    "    w0 = 0\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        scores = w0 + np.dot(features, weights)\n",
    "        predictions = (1 / (1 + np.exp(-scores)))\n",
    "#         print(scores.shape)\n",
    "#         print(predictions.shape)\n",
    "        # Update weights with gradient\n",
    "        output_error_signal = predictions - target\n",
    "#         print(output_error_signal.shape)\n",
    "        gradient = ( np.dot(features.T, output_error_signal)) + (regularizer*weights) #change\n",
    "        gradient = gradient * 1/m\n",
    "#         print(gradient.shape)\n",
    "        weights -= learning_rate * gradient \n",
    "        w0 = w0 - learning_rate*np.sum(output_error_signal) + learning_rate*regularizer\n",
    "        \n",
    "    return w0,weights\n",
    "\n",
    "def pred(w_star,w0, features):\n",
    "\n",
    "    ypred2 = np.zeros(y_test.shape[0])\n",
    "    for i in range(features.shape[0]):\n",
    "        scores = w0 + np.dot(w_star,features.T)     \n",
    "        prob = 1/(1 + np.exp(-np.dot(features[i],w_star)))\n",
    "        if(prob < 0.5):\n",
    "            ypred = 0\n",
    "        else:\n",
    "            ypred = 1\n",
    "        ypred2[i] = ypred\n",
    "    return ypred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train  --- change the hyperparams and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, weights = logistic_regression(X_train, y_train, 1500, 0.2 , 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights0 = logistic_regression(xtrain0, y0, 400, 0.0001 , 0.01)\n",
    "# weights1 = logistic_regression(xtrain1, y1, 1000,0.0001, 0.01)\n",
    "# weights2 = logistic_regression(xtrain2, y2, 100, 0.0001 ,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pred(weights,w0,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6144444444444445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyubomyr/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/lyubomyr/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5983333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)\n",
    "yy = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)\n",
    "accuracy_score(y_test, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyubomyr/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/lyubomyr/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5883333333333334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = pred(xtest0,weights0)\n",
    "pred1 = pred(xtest1,weights1)\n",
    "pred2 = pred(xtest2,weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform to the appropriate submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = np.append(np.append(pred0, pred1), pred2)\n",
    "col1 = range(0, 3000)\n",
    "preds = pd.DataFrame({'Id': col1, 'Bound': col2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_noleakage = preds.copy()\n",
    "sub_noleakage.Bound = 1*(sub_noleakage.Bound > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save without the trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_noleakage.to_csv('submission_final_no_leakage4.csv', sep=',', encoding='utf-8',index=False)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('submission_final_no_leakage4.csv')\n",
    "df_reorder = df[['Id','Bound']] # rearrange column here\n",
    "df_reorder.to_csv('submission_final.csv', sep=',', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5003333333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv('testY.csv')\n",
    "y_test = df[['Bound']]\n",
    "\n",
    "ypred = sub_noleakage[['Bound']]\n",
    "\n",
    "accuracy_score(y_test['Bound'], ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
